version: "3"

services:
  localchat-gpu:
    image: localchat-gpu:latest
    build: .
    command: sleep 10000
    environment:
    - MODEL_ID=TheBloke/Yarn-Llama-2-7B-128K-GGUF
    - MODEL_BASENAME=yarn-llama-2-7b-128k.Q4_K_M.gguf
    volumes:
    - ./models:/usr/src/localGPT/models
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  localchat-cpu:
    image: localchat-cpu:latest
    build: .
    command: sleep 10000
    environment:
    - MODEL_ID=TheBloke/Yarn-Llama-2-7B-128K-GGUF
    - MODEL_BASENAME=yarn-llama-2-7b-128k.Q4_K_M.gguf
    volumes:
    - ./models:/app/models
